{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFCx6jZU3m11"
   },
   "source": [
    "![title](securly-banner2.jpg)\n",
    "\n",
    "# Mistral for Discern - Fine Tune POC\n",
    "\n",
    "This notebook was adapted from this video: https://youtu.be/kmkcNVvEz-k?si=Ogt1wRFNqYI6zXfw&t=1\n",
    "\n",
    "We will use QLoRA, a fine-tuning method that combines quantization and LoRA. For more information about what those are and how they work, see [this post](https://brev.dev/blog/how-qlora-works).\n",
    "\n",
    "In this notebook, we will load the large model in 4bit using `bitsandbytes` and use LoRA to train using the PEFT library from Hugging Face ðŸ¤—."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Ideas for improvement\n",
    "* Larger Batch sizes\n",
    "* Randomize data order\n",
    "* Try on a bigger server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "Install libraries, load environment, etc.   You're going to need a .env file that looks like this:\n",
    "\n",
    "```bash\n",
    "ES_KEY_ID=\"HljH...\"\r\n",
    "ES_KEY=\"J2eGSPU...\"\n",
    "WANDB_API_KEY=\"asdasd....\"\n",
    "\n",
    "```\n",
    "\n",
    "Then we need to run the cells below once per new instance to set up support libraries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Channels:\n",
      " - defaults\n",
      " - nvidia\n",
      " - pytorch\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - matplotlib\n",
      "    - scikit-learn\n",
      "    - scipy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    brotli-1.0.9               |       h5eee18b_7          18 KB\n",
      "    brotli-bin-1.0.9           |       h5eee18b_7          19 KB\n",
      "    contourpy-1.2.0            |  py311hdb19cb5_0         263 KB\n",
      "    cycler-0.11.0              |     pyhd3eb1b0_0          12 KB\n",
      "    cyrus-sasl-2.1.28          |       h52b45da_1         237 KB\n",
      "    dbus-1.13.18               |       hb2f20db_0         504 KB\n",
      "    expat-2.5.0                |       h6a678d5_0         172 KB\n",
      "    fontconfig-2.14.1          |       h4c34cd2_2         281 KB\n",
      "    fonttools-4.25.0           |     pyhd3eb1b0_0         632 KB\n",
      "    glib-2.69.1                |       he621ea3_2         1.9 MB\n",
      "    gst-plugins-base-1.14.1    |       h6a678d5_1         2.2 MB\n",
      "    gstreamer-1.14.1           |       h5eee18b_1         1.7 MB\n",
      "    joblib-1.2.0               |  py311h06a4308_0         527 KB\n",
      "    kiwisolver-1.4.4           |  py311h6a678d5_0          70 KB\n",
      "    libbrotlicommon-1.0.9      |       h5eee18b_7          70 KB\n",
      "    libbrotlidec-1.0.9         |       h5eee18b_7          31 KB\n",
      "    libbrotlienc-1.0.9         |       h5eee18b_7         264 KB\n",
      "    libclang-14.0.6            |default_hc6dbbc7_1         137 KB\n",
      "    libclang13-14.0.6          |default_he11475f_1         9.8 MB\n",
      "    libcups-2.4.2              |       h2d74bed_1         4.5 MB\n",
      "    libgfortran-ng-11.2.0      |       h00389a5_1          20 KB\n",
      "    libgfortran5-11.2.0        |       h1234567_1         2.0 MB\n",
      "    libllvm14-14.0.6           |       hdb19cb5_3        33.4 MB\n",
      "    libpq-12.15                |       hdbd6064_1         2.4 MB\n",
      "    libxcb-1.15                |       h7f8727e_0         505 KB\n",
      "    libxkbcommon-1.0.1         |       h5eee18b_1         590 KB\n",
      "    matplotlib-3.8.0           |  py311h06a4308_0           8 KB\n",
      "    matplotlib-base-3.8.0      |  py311ha02d727_0         7.7 MB\n",
      "    munkres-1.1.4              |             py_0          13 KB\n",
      "    mysql-5.7.24               |       h721c034_2        60.0 MB\n",
      "    numpy-1.24.3               |  py311h08b1b3b_1          11 KB\n",
      "    numpy-base-1.24.3          |  py311hf175353_1         7.2 MB\n",
      "    pcre-8.45                  |       h295c915_0         207 KB\n",
      "    ply-3.11                   |  py311h06a4308_0         111 KB\n",
      "    pyparsing-3.0.9            |  py311h06a4308_0         204 KB\n",
      "    pyqt-5.15.10               |  py311h6a678d5_0         5.7 MB\n",
      "    pyqt5-sip-12.13.0          |  py311h5eee18b_0          95 KB\n",
      "    qt-main-5.15.2             |      h53bd1ea_10        53.7 MB\n",
      "    scikit-learn-1.3.0         |  py311ha02d727_0         9.5 MB\n",
      "    scipy-1.11.4               |  py311h08b1b3b_0        22.0 MB\n",
      "    sip-6.7.12                 |  py311h6a678d5_0         603 KB\n",
      "    threadpoolctl-2.2.0        |     pyh0d69192_0          16 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       229.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  brotli             pkgs/main/linux-64::brotli-1.0.9-h5eee18b_7 \n",
      "  brotli-bin         pkgs/main/linux-64::brotli-bin-1.0.9-h5eee18b_7 \n",
      "  contourpy          pkgs/main/linux-64::contourpy-1.2.0-py311hdb19cb5_0 \n",
      "  cycler             pkgs/main/noarch::cycler-0.11.0-pyhd3eb1b0_0 \n",
      "  cyrus-sasl         pkgs/main/linux-64::cyrus-sasl-2.1.28-h52b45da_1 \n",
      "  dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0 \n",
      "  expat              pkgs/main/linux-64::expat-2.5.0-h6a678d5_0 \n",
      "  fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-h4c34cd2_2 \n",
      "  fonttools          pkgs/main/noarch::fonttools-4.25.0-pyhd3eb1b0_0 \n",
      "  glib               pkgs/main/linux-64::glib-2.69.1-he621ea3_2 \n",
      "  gst-plugins-base   pkgs/main/linux-64::gst-plugins-base-1.14.1-h6a678d5_1 \n",
      "  gstreamer          pkgs/main/linux-64::gstreamer-1.14.1-h5eee18b_1 \n",
      "  joblib             pkgs/main/linux-64::joblib-1.2.0-py311h06a4308_0 \n",
      "  kiwisolver         pkgs/main/linux-64::kiwisolver-1.4.4-py311h6a678d5_0 \n",
      "  libbrotlicommon    pkgs/main/linux-64::libbrotlicommon-1.0.9-h5eee18b_7 \n",
      "  libbrotlidec       pkgs/main/linux-64::libbrotlidec-1.0.9-h5eee18b_7 \n",
      "  libbrotlienc       pkgs/main/linux-64::libbrotlienc-1.0.9-h5eee18b_7 \n",
      "  libclang           pkgs/main/linux-64::libclang-14.0.6-default_hc6dbbc7_1 \n",
      "  libclang13         pkgs/main/linux-64::libclang13-14.0.6-default_he11475f_1 \n",
      "  libcups            pkgs/main/linux-64::libcups-2.4.2-h2d74bed_1 \n",
      "  libgfortran-ng     pkgs/main/linux-64::libgfortran-ng-11.2.0-h00389a5_1 \n",
      "  libgfortran5       pkgs/main/linux-64::libgfortran5-11.2.0-h1234567_1 \n",
      "  libllvm14          pkgs/main/linux-64::libllvm14-14.0.6-hdb19cb5_3 \n",
      "  libpq              pkgs/main/linux-64::libpq-12.15-hdbd6064_1 \n",
      "  libxcb             pkgs/main/linux-64::libxcb-1.15-h7f8727e_0 \n",
      "  libxkbcommon       pkgs/main/linux-64::libxkbcommon-1.0.1-h5eee18b_1 \n",
      "  matplotlib         pkgs/main/linux-64::matplotlib-3.8.0-py311h06a4308_0 \n",
      "  matplotlib-base    pkgs/main/linux-64::matplotlib-base-3.8.0-py311ha02d727_0 \n",
      "  munkres            pkgs/main/noarch::munkres-1.1.4-py_0 \n",
      "  mysql              pkgs/main/linux-64::mysql-5.7.24-h721c034_2 \n",
      "  pcre               pkgs/main/linux-64::pcre-8.45-h295c915_0 \n",
      "  ply                pkgs/main/linux-64::ply-3.11-py311h06a4308_0 \n",
      "  pyparsing          pkgs/main/linux-64::pyparsing-3.0.9-py311h06a4308_0 \n",
      "  pyqt               pkgs/main/linux-64::pyqt-5.15.10-py311h6a678d5_0 \n",
      "  pyqt5-sip          pkgs/main/linux-64::pyqt5-sip-12.13.0-py311h5eee18b_0 \n",
      "  qt-main            pkgs/main/linux-64::qt-main-5.15.2-h53bd1ea_10 \n",
      "  scikit-learn       pkgs/main/linux-64::scikit-learn-1.3.0-py311ha02d727_0 \n",
      "  scipy              pkgs/main/linux-64::scipy-1.11.4-py311h08b1b3b_0 \n",
      "  sip                pkgs/main/linux-64::sip-6.7.12-py311h6a678d5_0 \n",
      "  threadpoolctl      pkgs/main/noarch::threadpoolctl-2.2.0-pyh0d69192_0 \n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  numpy                              1.26.2-py311h08b1b3b_0 --> 1.24.3-py311h08b1b3b_1 \n",
      "  numpy-base                         1.26.2-py311hf175353_0 --> 1.24.3-py311hf175353_1 \n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... \n",
      "\n",
      "    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.\n",
      "    More details are available here: https://intel.github.io/scikit-learn-intelex\n",
      "\n",
      "    For example:\n",
      "\n",
      "        $ conda install scikit-learn-intelex\n",
      "        $ python -m sklearnex my_application.py\n",
      "\n",
      "    \n",
      "\n",
      "done\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!conda install -qy scikit-learn scipy matplotlib\n",
    "!pip install -q -U python-dotenv\n",
    "!pip install -q -U  elasticsearch\n",
    "!pip install -q -U  datasets # The version in conda is broken?\n",
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install -q -U wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VC-9m2yv3m18"
   },
   "source": [
    "## Preparing data \n",
    "\n",
    "To prepare your dataset for loading, we need two `.jsonl` files structured something like this:\n",
    "```json\n",
    "{\"document\": \"journal-entry-for-model-to-predict\"}\n",
    "{\"document\": \"journal-entry-for-model-to-predict-1\"}\n",
    "{\"document\": \"journal-entry-for-model-to-predict-2\"}\n",
    "```\n",
    "\n",
    "You probably only need to do this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load keys and such from the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data from Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Variables</th>\n",
       "      <th>Note</th>\n",
       "      <th>AiTrainingPrompt</th>\n",
       "      <th>ExampleAiOutput</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[alexs, slope formula, aslope]</td>\n",
       "      <td>{'sports-and-athletics': 0.0, 'environmentalis...</td>\n",
       "      <td>The student searched for 'slope formula' which...</td>\n",
       "      <td>You are a Student Web Activity Analyzer develo...</td>\n",
       "      <td>{\\r\\n  \"sports-and-athletics\": \"1\",\\r\\n  \"spor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[adj, hellosmart]</td>\n",
       "      <td>{'sports-and-athletics': 0.0, 'environmentalis...</td>\n",
       "      <td>The search term 'adj' does not provide enough ...</td>\n",
       "      <td>You are a Student Web Activity Analyzer develo...</td>\n",
       "      <td>{\\r\\n  \"sports-and-athletics\": \"1\",\\r\\n  \"spor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[carrie fanart tawog, paswg art style, carrie ...</td>\n",
       "      <td>{'sports-and-athletics': 0.0, 'environmentalis...</td>\n",
       "      <td>The student's web activity shows a strong inte...</td>\n",
       "      <td>You are a Student Web Activity Analyzer develo...</td>\n",
       "      <td>{\\r\\n  \"sports-and-athletics\": \"1\",\\r\\n  \"spor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[how were marriages arranged in ancient babylo...</td>\n",
       "      <td>{'sports-and-athletics': 0.0, 'environmentalis...</td>\n",
       "      <td>The student's web activity indicates a strong ...</td>\n",
       "      <td>You are a Student Web Activity Analyzer develo...</td>\n",
       "      <td>{\\r\\n  \"sports-and-athletics\": \"1\",\\r\\n  \"spor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[kahoot join, lamborghini egoista  black, calc...</td>\n",
       "      <td>{'sports-and-athletics': 0.0, 'environmentalis...</td>\n",
       "      <td>The student's online activities include multip...</td>\n",
       "      <td>You are a Student Web Activity Analyzer develo...</td>\n",
       "      <td>{\\r\\n  \"sports-and-athletics\": \"1\",\\r\\n  \"spor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54480</th>\n",
       "      <td>[the war overseas had been causing the price o...</td>\n",
       "      <td>{'parental-absence': 0.0, 'academic-poor-perfo...</td>\n",
       "      <td>The online activities consist of searches rela...</td>\n",
       "      <td>You are an AI designed to conduct a School Vio...</td>\n",
       "      <td>{\\r\\n  \"parental-absence\": \"1\",\\r\\n  \"parental...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54481</th>\n",
       "      <td>[a process that is used to gain knowledge abou...</td>\n",
       "      <td>{'parental-absence': 0.0, 'academic-poor-perfo...</td>\n",
       "      <td>The online activities consist primarily of aca...</td>\n",
       "      <td>You are an AI designed to conduct a School Vio...</td>\n",
       "      <td>{\\r\\n  \"parental-absence\": \"1\",\\r\\n  \"parental...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54482</th>\n",
       "      <td>[words that modify or describe nouns, verbs th...</td>\n",
       "      <td>{'parental-absence': 0.0, 'academic-poor-perfo...</td>\n",
       "      <td>The online activities consist of searches rela...</td>\n",
       "      <td>You are an AI designed to conduct a School Vio...</td>\n",
       "      <td>{\\r\\n  \"parental-absence\": \"1\",\\r\\n  \"parental...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54483</th>\n",
       "      <td>[freshman math problems, hard math problems wi...</td>\n",
       "      <td>{'parental-absence': 0.0, 'academic-poor-perfo...</td>\n",
       "      <td>The student appears to be engaging in typical ...</td>\n",
       "      <td>You are an AI designed to conduct a School Vio...</td>\n",
       "      <td>{\\r\\n  \"parental-absence\": \"1\",\\r\\n  \"parental...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54484</th>\n",
       "      <td>[what did confucius emphasize most about socie...</td>\n",
       "      <td>{'parental-absence': 0.0, 'academic-poor-perfo...</td>\n",
       "      <td>The online activities involve educational sear...</td>\n",
       "      <td>You are an AI designed to conduct a School Vio...</td>\n",
       "      <td>{\\r\\n  \"parental-absence\": \"1\",\\r\\n  \"parental...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54485 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Keywords  \\\n",
       "0                         [alexs, slope formula, aslope]   \n",
       "1                                      [adj, hellosmart]   \n",
       "2      [carrie fanart tawog, paswg art style, carrie ...   \n",
       "3      [how were marriages arranged in ancient babylo...   \n",
       "4      [kahoot join, lamborghini egoista  black, calc...   \n",
       "...                                                  ...   \n",
       "54480  [the war overseas had been causing the price o...   \n",
       "54481  [a process that is used to gain knowledge abou...   \n",
       "54482  [words that modify or describe nouns, verbs th...   \n",
       "54483  [freshman math problems, hard math problems wi...   \n",
       "54484  [what did confucius emphasize most about socie...   \n",
       "\n",
       "                                               Variables  \\\n",
       "0      {'sports-and-athletics': 0.0, 'environmentalis...   \n",
       "1      {'sports-and-athletics': 0.0, 'environmentalis...   \n",
       "2      {'sports-and-athletics': 0.0, 'environmentalis...   \n",
       "3      {'sports-and-athletics': 0.0, 'environmentalis...   \n",
       "4      {'sports-and-athletics': 0.0, 'environmentalis...   \n",
       "...                                                  ...   \n",
       "54480  {'parental-absence': 0.0, 'academic-poor-perfo...   \n",
       "54481  {'parental-absence': 0.0, 'academic-poor-perfo...   \n",
       "54482  {'parental-absence': 0.0, 'academic-poor-perfo...   \n",
       "54483  {'parental-absence': 0.0, 'academic-poor-perfo...   \n",
       "54484  {'parental-absence': 0.0, 'academic-poor-perfo...   \n",
       "\n",
       "                                                    Note  \\\n",
       "0      The student searched for 'slope formula' which...   \n",
       "1      The search term 'adj' does not provide enough ...   \n",
       "2      The student's web activity shows a strong inte...   \n",
       "3      The student's web activity indicates a strong ...   \n",
       "4      The student's online activities include multip...   \n",
       "...                                                  ...   \n",
       "54480  The online activities consist of searches rela...   \n",
       "54481  The online activities consist primarily of aca...   \n",
       "54482  The online activities consist of searches rela...   \n",
       "54483  The student appears to be engaging in typical ...   \n",
       "54484  The online activities involve educational sear...   \n",
       "\n",
       "                                        AiTrainingPrompt  \\\n",
       "0      You are a Student Web Activity Analyzer develo...   \n",
       "1      You are a Student Web Activity Analyzer develo...   \n",
       "2      You are a Student Web Activity Analyzer develo...   \n",
       "3      You are a Student Web Activity Analyzer develo...   \n",
       "4      You are a Student Web Activity Analyzer develo...   \n",
       "...                                                  ...   \n",
       "54480  You are an AI designed to conduct a School Vio...   \n",
       "54481  You are an AI designed to conduct a School Vio...   \n",
       "54482  You are an AI designed to conduct a School Vio...   \n",
       "54483  You are an AI designed to conduct a School Vio...   \n",
       "54484  You are an AI designed to conduct a School Vio...   \n",
       "\n",
       "                                         ExampleAiOutput  \n",
       "0      {\\r\\n  \"sports-and-athletics\": \"1\",\\r\\n  \"spor...  \n",
       "1      {\\r\\n  \"sports-and-athletics\": \"1\",\\r\\n  \"spor...  \n",
       "2      {\\r\\n  \"sports-and-athletics\": \"1\",\\r\\n  \"spor...  \n",
       "3      {\\r\\n  \"sports-and-athletics\": \"1\",\\r\\n  \"spor...  \n",
       "4      {\\r\\n  \"sports-and-athletics\": \"1\",\\r\\n  \"spor...  \n",
       "...                                                  ...  \n",
       "54480  {\\r\\n  \"parental-absence\": \"1\",\\r\\n  \"parental...  \n",
       "54481  {\\r\\n  \"parental-absence\": \"1\",\\r\\n  \"parental...  \n",
       "54482  {\\r\\n  \"parental-absence\": \"1\",\\r\\n  \"parental...  \n",
       "54483  {\\r\\n  \"parental-absence\": \"1\",\\r\\n  \"parental...  \n",
       "54484  {\\r\\n  \"parental-absence\": \"1\",\\r\\n  \"parental...  \n",
       "\n",
       "[54485 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import pandas as pd\n",
    "\n",
    "es = Elasticsearch(\n",
    "    'https://elastic-ksi-prod.es.us-east-1.aws.found.io:443',\n",
    "    api_key=(os.getenv(\"ES_KEY_ID\"), os.getenv(\"ES_KEY\")),                  # Use this if you have an API key\n",
    ")\n",
    "\n",
    "# Define and Execute Query\n",
    "query = {\n",
    "    \"_source\": [\"AiTrainingPrompt\", \"Keywords\", \"ExampleAiOutput\", \"Variables\", \"Note\"],\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\"match\": {\"ClinicalFrameworkName\": \"Students' Interests - Alpha\"}},\n",
    "                {\"match\": {\"IsSuccess\": True}}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "scroll_timeout = \"10m\"\n",
    "response  = es.search(index=\"prod-gpt-response\", body=query, scroll=scroll_timeout, size=1000)\n",
    "scroll_id = response['_scroll_id']\n",
    "hits = response['hits']['hits']\n",
    "\n",
    "while True:\n",
    "    response = es.scroll(scroll_id=scroll_id, scroll=scroll_timeout)\n",
    "\n",
    "    if not response['hits']['hits']:\n",
    "        break\n",
    "\n",
    "    scroll_id = response['_scroll_id']\n",
    "    hits.extend(response['hits']['hits'])\n",
    "\n",
    "# Process and Display Data\n",
    "data = pd.DataFrame([hit['_source'] for hit in hits])\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54485"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting the data back into a single message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Question:\n",
      "You are a Student Web Activity Analyzer developed to support professionals, including Social Workers, School Psychologists, District Administrators, School Safety Specialists, and related roles. Your primary objective is to meticulously evaluate the online activity of K-12 students and identify specific indicators related to their interests and passions. For each identified indicator, provide a JSON object containing:\n",
      "\n",
      "Presence: Indicate a value of 1 (if the indicator is present) or 0 (if not). Even if only a portion of the data aligns with an indicator, mark it as 1.\n",
      "Confidence: Assign a confidence level on a scale of 1-10 to indicate the certainty level of your analysis.\n",
      "\n",
      "Additionally, please include a note that outlines the rationale behind identifying certain indicators and offers a summary of the analyzed web activity.\n",
      "\n",
      "Adhere to the JSON format outlined in the example output section precisely.\n",
      "\n",
      "Each individual online activity you receive represents one search or interaction on a student's device. Occasionally, searches that include large amounts of text will be summarized. These summaries will be marked with 'S~'. Such summarization typically occurs when students copy and paste extensive text blocks, although other cases may exist. Additional details will be provided in the summary.\n",
      "\n",
      "In situations where the presence of an indicator is ambiguous or if anomalies are present in the data, exercise your best judgment while providing a confidence level that reflects the level of uncertainty.\n",
      "\n",
      "Here are the specific indicators that you should use for this task, with definitions, delimited by single quotes.\n",
      "\n",
      "'sports-and-athletics: participating in physical activities and team sports to promote fitness, teamwork, and sportsmanship.'\n",
      "'environmentalism-and-sustainability: learning about the environment, conservation, and sustainable practices to become responsible global citizens.'\n",
      "'gaming-and-e-sports: engaging in digital gaming and competitive e-sports to develop strategic thinking, problem-solving, and teamwork skills.'\n",
      "'college-and-career: engaging in planning, research, and/or discovery around future college and career opportunities or otherwise demonstrating an interest in college or career activities after high school'\n",
      "'cooking-and-food: investigating cooking or food'\n",
      "'reading-and-literature: exploring the world of books and stories through reading and interpretation.'\n",
      "'writing-and-creative-writing: expressing thoughts, ideas, and imagination through written words and storytelling.'\n",
      "'science-and-technology: investigating the natural world and technological advancements'\n",
      "'mathematics-and-statistics: engaging in problem-solving and numerical analysis to understand patterns, shapes, and quantities.'\n",
      "'history-and-social-studies: discovering past events, cultures, and societies to gain a deeper understanding of the world.'\n",
      "'creative-arts: expressing creativity through various art forms like drawing, painting, sculpture, music, performing arts, and more'\n",
      "'animals-and-nature: reflects a student's enthusiasm and curiosity for studying, observing, or interacting with animals and natural environments, potentially driving academic pursuits, extracurricular activities, or career paths related to biology, ecology, or conservation.'\n",
      "\n",
      "\n",
      "### Search Data:\n",
      "['alexs', 'slope formula', 'aslope']\n",
      "\n",
      "### Example Output:\n",
      "{\n",
      "  \"sports-and-athletics\": \"1\",\n",
      "  \"sports-and-athletics-confidence\": \"6\",\n",
      "  \"environmentalism-and-sustainability\": \"0\",\n",
      "  \"environmentalism-and-sustainability-confidence\": \"8\",\n",
      "  \"gaming-and-e-sports\": \"0\",\n",
      "  \"gaming-and-e-sports-confidence\": \"10\",\n",
      "  \"college-and-career\": \"1\",\n",
      "  \"college-and-career-confidence\": \"7\",\n",
      "  \"cooking-and-food\": \"1\",\n",
      "  \"cooking-and-food-confidence\": \"7\",\n",
      "  \"reading-and-literature\": \"0\",\n",
      "  \"reading-and-literature-confidence\": \"7\",\n",
      "  \"writing-and-creative-writing\": \"1\",\n",
      "  \"writing-and-creative-writing-confidence\": \"8\",\n",
      "  \"science-and-technology\": \"0\",\n",
      "  \"science-and-technology-confidence\": \"10\",\n",
      "  \"mathematics-and-statistics\": \"1\",\n",
      "  \"mathematics-and-statistics-confidence\": \"6\",\n",
      "  \"history-and-social-studies\": \"9\",\n",
      "  \"history-and-social-studies-confidence\": \"0\",\n",
      "  \"creative-arts\": \"1\",\n",
      "  \"creative-arts-confidence\": \"8\",\n",
      "  \"animals-and-nature\": \"1\",\n",
      "  \"animals-and-nature-confidence\": \"9\",\n",
      "  \"note\": \"Detailed Summary Goes Here \"\n",
      "}\n",
      "\n",
      "### Solution:\n",
      "{\n",
      "  \"sports-and-athletics\": \"0.0\",\n",
      "  \"sports-and-athletics-confidence\": \"10.0\",\n",
      "  \"environmentalism-and-sustainability\": \"0.0\",\n",
      "  \"environmentalism-and-sustainability-confidence\": \"10.0\",\n",
      "  \"gaming-and-e-sports\": \"0.0\",\n",
      "  \"gaming-and-e-sports-confidence\": \"10.0\",\n",
      "  \"college-and-career\": \"0.0\",\n",
      "  \"college-and-career-confidence\": \"10.0\",\n",
      "  \"cooking-and-food\": \"0.0\",\n",
      "  \"cooking-and-food-confidence\": \"10.0\",\n",
      "  \"reading-and-literature\": \"0.0\",\n",
      "  \"reading-and-literature-confidence\": \"10.0\",\n",
      "  \"writing-and-creative-writing\": \"0.0\",\n",
      "  \"writing-and-creative-writing-confidence\": \"10.0\",\n",
      "  \"science-and-technology\": \"0.0\",\n",
      "  \"science-and-technology-confidence\": \"10.0\",\n",
      "  \"mathematics-and-statistics\": \"1.0\",\n",
      "  \"mathematics-and-statistics-confidence\": \"9.0\",\n",
      "  \"history-and-social-studies\": \"0.0\",\n",
      "  \"history-and-social-studies-confidence\": \"10.0\",\n",
      "  \"creative-arts\": \"0.0\",\n",
      "  \"creative-arts-confidence\": \"10.0\",\n",
      "  \"animals-and-nature\": \"0.0\",\n",
      "  \"animals-and-nature-confidence\": \"10.0\",\n",
      "  \"note\": \"The student searched for 'slope formula' which is related to mathematics, indicating an interest or homework activity in this subject. The confidence is high due to the specific nature of the search term. The other search term 'alexs' is ambiguous and does not provide enough context to confidently associate with any of the given indicators.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def question_func(data):\n",
    "    question = \"\"\"### Question:\n",
    "{prompt}\n",
    "\n",
    "### Search Data:\n",
    "{searches}\n",
    "\n",
    "### Example Output:\n",
    "{example}\n",
    "\n",
    "### Solution:\"\"\".format(prompt=data['AiTrainingPrompt'], searches=data['Keywords'], example=data['ExampleAiOutput'])\n",
    "\n",
    "    return question\n",
    "\n",
    "def solution_func(data):\n",
    "    solution = \"\"\"\n",
    "{{\n",
    "  \"sports-and-athletics\": \"{sportsandathletics}\",\n",
    "  \"sports-and-athletics-confidence\": \"{sportsandathleticsconfidence}\",\n",
    "  \"environmentalism-and-sustainability\": \"{environmentalismandsustainability}\",\n",
    "  \"environmentalism-and-sustainability-confidence\": \"{environmentalismandsustainabilityconfidence}\",\n",
    "  \"gaming-and-e-sports\": \"{gamingandesports}\",\n",
    "  \"gaming-and-e-sports-confidence\": \"{gamingandesportsconfidence}\",\n",
    "  \"college-and-career\": \"{collegeandcareer}\",\n",
    "  \"college-and-career-confidence\": \"{collegeandcareerconfidence}\",\n",
    "  \"cooking-and-food\": \"{cookingandfood}\",\n",
    "  \"cooking-and-food-confidence\": \"{cookingandfoodconfidence}\",\n",
    "  \"reading-and-literature\": \"{readingandliterature}\",\n",
    "  \"reading-and-literature-confidence\": \"{readingandliteratureconfidence}\",\n",
    "  \"writing-and-creative-writing\": \"{writingandcreativewriting}\",\n",
    "  \"writing-and-creative-writing-confidence\": \"{writingandcreativewritingconfidence}\",\n",
    "  \"science-and-technology\": \"{scienceandtechnology}\",\n",
    "  \"science-and-technology-confidence\": \"{scienceandtechnologyconfidence}\",\n",
    "  \"mathematics-and-statistics\": \"{mathematicsandstatistics}\",\n",
    "  \"mathematics-and-statistics-confidence\": \"{mathematicsandstatisticsconfidence}\",\n",
    "  \"history-and-social-studies\": \"{historyandsocialstudies}\",\n",
    "  \"history-and-social-studies-confidence\": \"{historyandsocialstudiesconfidence}\",\n",
    "  \"creative-arts\": \"{creativearts}\",\n",
    "  \"creative-arts-confidence\": \"{creativeartsconfidence}\",\n",
    "  \"animals-and-nature\": \"{animalsandnature}\",\n",
    "  \"animals-and-nature-confidence\": \"{animalsandnatureconfidence}\",\n",
    "  \"note\": \"{note}\"\n",
    "}}\"\"\".format(sportsandathletics=data['Variables']['sports-and-athletics'],\n",
    "            sportsandathleticsconfidence=data['Variables']['sports-and-athletics-confidence'],\n",
    "            environmentalismandsustainability=data['Variables']['environmentalism-and-sustainability'],\n",
    "            environmentalismandsustainabilityconfidence=data['Variables']['environmentalism-and-sustainability-confidence'],\n",
    "            gamingandesports=data['Variables']['gaming-and-e-sports'],\n",
    "            gamingandesportsconfidence=data['Variables']['gaming-and-e-sports-confidence'],\n",
    "            collegeandcareer=data['Variables']['college-and-career'],\n",
    "            collegeandcareerconfidence=data['Variables']['college-and-career-confidence'],\n",
    "            cookingandfood=data['Variables']['cooking-and-food'],\n",
    "            cookingandfoodconfidence=data['Variables']['cooking-and-food-confidence'],\n",
    "            readingandliterature=data['Variables']['reading-and-literature'],\n",
    "            readingandliteratureconfidence=data['Variables']['reading-and-literature-confidence'],\n",
    "            writingandcreativewriting=data['Variables']['writing-and-creative-writing'],\n",
    "            writingandcreativewritingconfidence=data['Variables']['writing-and-creative-writing-confidence'],\n",
    "            scienceandtechnology=data['Variables']['science-and-technology'],\n",
    "            scienceandtechnologyconfidence=data['Variables']['science-and-technology-confidence'],\n",
    "            mathematicsandstatistics=data['Variables']['mathematics-and-statistics'],\n",
    "            mathematicsandstatisticsconfidence=data['Variables']['mathematics-and-statistics-confidence'],\n",
    "            historyandsocialstudies=data['Variables']['history-and-social-studies'],\n",
    "            historyandsocialstudiesconfidence=data['Variables']['history-and-social-studies-confidence'],\n",
    "            creativearts=data['Variables']['creative-arts'],\n",
    "            creativeartsconfidence=data['Variables']['creative-arts-confidence'],\n",
    "            animalsandnature=data['Variables']['animals-and-nature'],\n",
    "            animalsandnatureconfidence=data['Variables']['animals-and-nature-confidence'],\n",
    "            note=data['Note']\n",
    ")\n",
    "    \n",
    "    return solution\n",
    "\n",
    "def formatting_func(data):\n",
    "    try:\n",
    "        question = question_func(data)\n",
    "        solution = solution_func(data)\n",
    "        return question+solution\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "print(formatting_func(data.loc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ### Question:\\nYou are a Student Web Activity ...\n",
       "1        ### Question:\\nYou are a Student Web Activity ...\n",
       "2        ### Question:\\nYou are a Student Web Activity ...\n",
       "3        ### Question:\\nYou are a Student Web Activity ...\n",
       "4        ### Question:\\nYou are a Student Web Activity ...\n",
       "                               ...                        \n",
       "22662    ### Question:\\nYou are a Student Web Activity ...\n",
       "22663    ### Question:\\nYou are a Student Web Activity ...\n",
       "22664    ### Question:\\nYou are a Student Web Activity ...\n",
       "22665    ### Question:\\nYou are a Student Web Activity ...\n",
       "22666    ### Question:\\nYou are a Student Web Activity ...\n",
       "Length: 22660, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the formatting function and filter out any documents that fail to format\n",
    "documents = data.apply(formatting_func, axis=1).loc[lambda x : x != 0]\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, val_data = train_test_split(documents, test_size=0.02, random_state=42)\n",
    "\n",
    "train_df = pd.DataFrame(train_data)\n",
    "train_df.columns = ['document']\n",
    "val_df = pd.DataFrame(val_data)\n",
    "val_df.columns = ['document']\n",
    "\n",
    "train_df.to_json('train_data.jsonl', orient='records', lines=True)\n",
    "val_df.to_json('validation_data.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Data Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "s6f4z8EYmcJ6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e164449fb04c4a05a25fb5791bdbfbb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922f25f306194de6acd6eb04bfe0959a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27230de059f340baa077f8c03d4923dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f8fa681c194caa9c60a05feaf6f07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb69c83bb934c8c9d75608d28164d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f01e0f065741a382c4a4d4e5d09e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"json\", data_files='./train_data.jsonl', split='train')\n",
    "eval_dataset = load_dataset(\"json\", data_files='./validation_data.jsonl', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shz8Xdv-yRgf"
   },
   "source": [
    "### Load Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJ-5idQwzvg-"
   },
   "source": [
    "Let's now load Mistral - mistralai/Mistral-7B-v0.1 - using 4-bit quantization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "45524c98039a46d5b7745ad7cb638d2f"
     ]
    },
    "id": "E0Nl5mWL0k2T",
    "outputId": "47b6b01d-e9f2-4b70-919c-17ae64993843"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3e7fdfa05a4af58b24b98874c0067f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ffd49baaa12440a87db1f168762b0d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397650687db245669fb1e9fe3fc0dcb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8342d7c7686e44c68e7ea4f66075d5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199cb99588db44b8ae9504b9518e1ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/5.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f857b5bee3742e098ccd300e9d3bef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0621094d3c25497ca2de61d1b8cb0358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjNdXolqyRgf"
   },
   "source": [
    "### Tokenize the training and validation sets\n",
    "\n",
    "Set up the tokenizer. Add padding on the left as it [makes training use less memory](https://ai.stackexchange.com/questions/41485/while-fine-tuning-a-decoder-only-llm-like-llama-on-chat-dataset-what-kind-of-pa).\n",
    "\n",
    "For `model_max_length`, it's helpful to get a distribution of your data lengths. Let's first tokenize without the truncation/padding, so we can get a length distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "haSUDD9HyRgf",
    "outputId": "22ee95db-2974-4ab0-e0c7-444d04d3e838"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcea611cd4c0400dbd81d964436eb964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/966 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481fdbfeb29a4e2887625a3201dc0763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e6ca73abf841d7ad552e82ccf125a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292060316ba64c59977c7b38fadd1b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize_prompt(prompt):\n",
    "    return tokenizer(prompt['document'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHnKLcq4yRgg"
   },
   "source": [
    "Reformat the prompt and tokenize each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "S3iLAwLh3m19"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2b195e3cd4446ba0ef0ab16a397ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22206 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72d8413387841559d271f686a092e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/454 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(tokenize_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6ewk27p3m19"
   },
   "source": [
    "### Check distribution of data and data training lengths\n",
    "\n",
    "Let's get a distribution of our dataset lengths, so we can determine the appropriate `max_length` for our input tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BA8M9yfC3m19",
    "outputId": "99c6d302-9bb6-47b1-cae9-a1cd870b4770"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=100, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35449a5dbf94a4083026943df43043d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/22206 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71ccf31fde84fc28d35b68c29f8965d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/454 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Truncate down to something reasonable for training\n",
    "\n",
    "max_length = 2000 # This was an appropriate max length for my dataset\n",
    "\n",
    "def filter_long_records(record):\n",
    "    return len(record['input_ids']) <= max_length\n",
    "\n",
    "# Apply the filter function to your dataset\n",
    "tokenized_train_dataset = tokenized_train_dataset.filter(filter_long_records)    \n",
    "tokenized_val_dataset = tokenized_val_dataset.filter(filter_long_records)\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBk4Qp_vyRgh"
   },
   "source": [
    "From here, you can choose where you'd like to set the `max_length` to be. You can truncate and pad training examples to fit them to your chosen size. Be aware that choosing a larger `max_length` has its compute tradeoffs.\n",
    "\n",
    "I'm using my personal notes to train the model, and they vary greatly in length. I spent some time cleaning the dataset so the samples were about the same length, cutting up individual notes if needed, but being sure to not cut in the middle of a word or sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMlw8h743m19"
   },
   "source": [
    "Now let's tokenize again with padding and truncation, and set up the tokenize function to make labels and input_ids the same. This is basically what [self-supervised fine-tuning is](https://neptune.ai/blog/self-supervised-learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "acINaViR3m19"
   },
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        prompt['document'],\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "518d4f0b89bf4d57bf00d4c6d6e59eb5"
     ]
    },
    "id": "lTk-aTog3m19",
    "outputId": "4fb637b4-77a2-47c6-de7b-4fb620663dd7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9834f0775aac41bfa6a81c9d24e7e67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22206 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d264e1798ea1447980cce9d7242ba7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/454 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQL796OayRgh"
   },
   "source": [
    "Check that `input_ids` is padded on the left with the `eos_token` (2) and there is an `eos_token` 2 added to the end, and the prompt starts with a `bos_token` (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OKHhvxK83m19",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 774, 22478, 28747, 13, 1976, 460, 264, 15965, 6353, 24066, 1094, 8910, 3506, 6202, 298, 1760, 12749, 28725, 2490, 7575, 5066, 404, 28725, 4228, 17221, 17736, 28725, 8207, 11790, 3117, 28725, 4228, 19412, 8942, 1583, 28725, 304, 5202, 12426, 28723, 3604, 6258, 13640, 349, 298, 1424, 294, 26344, 15627, 272, 3270, 6355, 302, 524, 28733, 28740, 28750, 3567, 304, 9051, 2948, 4073, 3117, 5202, 298, 652, 10299, 304, 1455, 594, 28723, 1263, 1430, 10248, 24492, 28725, 3084, 264, 9292, 1928, 8707, 28747, 13, 13, 19167, 636, 28747, 330, 1192, 302, 28705, 28740, 325, 335, 272, 24492, 349, 2169, 28731, 442, 28705, 28734, 325, 335, 459, 609, 3655, 390, 28705, 28740, 1019, 513, 865, 744, 302, 272, 1178, 8753, 28713, 395, 396, 24492, 28723, 13, 10193, 3164, 28747, 7133, 547, 264, 9843, 2184, 356, 264, 5657, 302, 28705, 28740, 28733, 28740, 28734, 298, 11634, 574, 2184, 302, 2552, 884, 297, 272, 5643, 28723, 13, 12205, 28747, 560, 12856, 1871, 356, 272, 11408, 1307, 298, 7964, 369, 2552, 4073, 3117, 654, 10248, 304, 264, 14060, 302, 272, 28649, 4686, 6355, 28723, 13, 13, 21432, 1184, 11533, 297, 272, 1178, 28725, 459, 776, 3235, 15321, 1927, 28723, 13, 13, 21432, 1184, 369, 272, 3270, 6355, 5016, 1002, 477, 264, 2052, 28733, 815, 2465, 3895, 28723, 13, 13, 3381, 25787, 10741, 938, 574, 1489, 16548, 28725, 7967, 18110, 297, 9843, 7420, 28723, 13, 13, 15423, 460, 272, 2948, 4073, 3117, 354, 456, 3638, 8230, 13, 28801, 13, 28742, 28713, 2729, 28733, 391, 28733, 498, 895, 1063, 27732, 13, 28742, 21680, 282, 1443, 28733, 391, 28733, 28713, 27301, 2437, 27732, 13, 28742, 28721, 6133, 28733, 391, 28733, 28706, 28733, 28713, 2729, 27732, 13, 28742, 1396, 3528, 28733, 391, 28733, 8001, 263, 27732, 13, 28742, 27177, 288, 28733, 391, 28733, 18972, 27732, 13, 28742, 923, 288, 28733, 391, 28733, 24477, 1373, 27732, 13, 28742, 19061, 28733, 391, 28733, 16346, 495, 28733, 19061, 27732, 13, 28742, 17819, 28733, 391, 28733, 23207, 2161, 27732, 13, 28742, 3076, 11953, 1063, 28733, 391, 28733, 5975, 5513, 27732, 13, 28742, 16346, 495, 28733, 8060, 27732, 13, 28742, 12714, 973, 28733, 391, 28733, 28711, 1373, 27732, 13, 28742, 15205, 28733, 391, 28733, 22698, 28733, 13082, 497, 27732, 13, 13, 13, 27332, 11147, 5284, 28747, 13, 1410, 19185, 465, 28724, 647, 464, 1189, 322, 28724, 3500, 19521, 647, 464, 893, 24100, 3500, 19521, 1421, 13, 13, 27332, 16693, 15985, 28747, 13, 4441, 13, 28705, 345, 28713, 2729, 28733, 391, 28733, 498, 895, 1063, 1264, 345, 28740, 10939, 13, 28705, 345, 28713, 2729, 28733, 391, 28733, 498, 895, 1063, 28733, 5552, 3164, 1264, 345, 28784, 10939, 13, 28705, 345, 21680, 282, 1443, 28733, 391, 28733, 28713, 27301, 2437, 1264, 345, 28734, 10939, 13, 28705, 345, 21680, 282, 1443, 28733, 391, 28733, 28713, 27301, 2437, 28733, 5552, 3164, 1264, 345, 28783, 10939, 13, 28705, 345, 28721, 6133, 28733, 391, 28733, 28706, 28733, 28713, 2729, 1264, 345, 28734, 10939, 13, 28705, 345, 28721, 6133, 28733, 391, 28733, 28706, 28733, 28713, 2729, 28733, 5552, 3164, 1264, 345, 28740, 28734, 10939, 13, 28705, 345, 1396, 3528, 28733, 391, 28733, 8001, 263, 1264, 345, 28740, 10939, 13, 28705, 345, 1396, 3528, 28733, 391, 28733, 8001, 263, 28733, 5552, 3164, 1264, 345, 28787, 10939, 13, 28705, 345, 27177, 288, 28733, 391, 28733, 18972, 1264, 345, 28740, 10939, 13, 28705, 345, 27177, 288, 28733, 391, 28733, 18972, 28733, 5552, 3164, 1264, 345, 28787, 10939, 13, 28705, 345, 923, 288, 28733, 391, 28733, 24477, 1373, 1264, 345, 28734, 10939, 13, 28705, 345, 923, 288, 28733, 391, 28733, 24477, 1373, 28733, 5552, 3164, 1264, 345, 28787, 10939, 13, 28705, 345, 19061, 28733, 391, 28733, 16346, 495, 28733, 19061, 1264, 345, 28740, 10939, 13, 28705, 345, 19061, 28733, 391, 28733, 16346, 495, 28733, 19061, 28733, 5552, 3164, 1264, 345, 28783, 10939, 13, 28705, 345, 17819, 28733, 391, 28733, 23207, 2161, 1264, 345, 28734, 10939, 13, 28705, 345, 17819, 28733, 391, 28733, 23207, 2161, 28733, 5552, 3164, 1264, 345, 28740, 28734, 10939, 13, 28705, 345, 3076, 11953, 1063, 28733, 391, 28733, 5975, 5513, 1264, 345, 28740, 10939, 13, 28705, 345, 3076, 11953, 1063, 28733, 391, 28733, 5975, 5513, 28733, 5552, 3164, 1264, 345, 28784, 10939, 13, 28705, 345, 16346, 495, 28733, 8060, 1264, 345, 28740, 10939, 13, 28705, 345, 16346, 495, 28733, 8060, 28733, 5552, 3164, 1264, 345, 28783, 10939, 13, 28705, 345, 12714, 973, 28733, 391, 28733, 28711, 1373, 1264, 345, 28740, 10939, 13, 28705, 345, 12714, 973, 28733, 391, 28733, 28711, 1373, 28733, 5552, 3164, 1264, 345, 28774, 10939, 13, 28705, 345, 15205, 28733, 391, 28733, 22698, 28733, 13082, 497, 1264, 345, 28734, 10939, 13, 28705, 345, 15205, 28733, 391, 28733, 22698, 28733, 13082, 497, 28733, 5552, 3164, 1264, 345, 28774, 10939, 13, 28705, 345, 8838, 1264, 345, 5155, 2384, 23276, 3187, 274, 4003, 345, 28801, 13, 28752, 13, 13, 27332, 27786, 28747, 13, 28751, 13, 28705, 345, 28713, 2729, 28733, 391, 28733, 498, 895, 1063, 1264, 345, 28734, 28723, 28734, 548, 13, 28705, 345, 28713, 2729, 28733, 391, 28733, 498, 895, 1063, 28733, 5552, 3164, 1264, 345, 28740, 28734, 28723, 28734, 548, 13, 28705, 345, 21680, 282, 1443, 28733, 391, 28733, 28713, 27301, 2437, 1264, 345, 28734, 28723, 28734, 548, 13, 28705, 345, 21680, 282, 1443, 28733, 391, 28733, 28713, 27301, 2437, 28733, 5552, 3164, 1264, 345, 28740, 28734, 28723, 28734, 548, 13, 28705, 345, 28721, 6133, 28733, 391, 28733, 28706, 28733, 28713, 2729, 1264, 345, 28734, 28723, 28734, 548, 13, 28705, 345, 28721, 6133, 28733, 391, 28733, 28706, 28733, 28713, 2729, 28733, 5552, 3164, 1264, 345, 28740, 28734, 28723, 28734, 548, 13, 28705, 345, 1396, 3528, 28733, 391, 28733, 8001, 263, 1264, 345, 28734, 28723, 28734, 548, 13, 28705, 345, 1396, 3528, 28733, 391, 28733, 8001, 263, 28733, 5552, 3164, 1264, 345, 28740, 28734, 28723, 28734, 548, 13, 28705, 345, 27177, 288, 28733, 391, 28733, 18972, 1264, 345, 28734, 28723, 28734, 548, 13, 28705, 345, 27177, 288, 28733, 391, 28733, 18972, 28733, 5552, 3164, 1264, 345, 28740, 28734, 28723, 28734, 548, 13, 28705, 345, 923, 288, 28733, 391, 28733, 24477, 1373, 1264, 345, 28734, 28723, 28734, 548, 13, 28705, 345, 923, 288, 28733, 391, 28733, 24477, 1373, 28733, 5552, 3164, 1264, 345, 28740, 28734, 28723, 28734, 548, 13, 28705, 345, 19061, 28733, 391, 28733, 16346, 495, 28733, 19061, 1264, 345, 28734, 28723, 28734, 548, 13, 28705, 345, 19061, 28733, 391, 28733, 16346, 495, 28733, 19061, 28733, 5552, 3164, 1264, 345, 28740, 28734, 28723, 28734, 548, 13, 28705, 345, 17819, 28733, 391, 28733, 23207, 2161, 1264, 345, 28734, 28723, 28734, 548, 13, 28705, 345, 17819, 28733, 391, 28733, 23207, 2161, 28733, 5552, 3164, 1264, 345, 28740, 28734, 28723, 28734, 548, 13, 28705, 345, 3076, 11953, 1063, 28733, 391, 28733, 5975, 5513, 1264, 345, 28734, 28723, 28734, 548, 13, 28705, 345, 3076, 11953, 1063, 28733, 391, 28733, 5975, 5513, 28733, 5552, 3164, 1264, 345, 28740, 28734, 28723, 28734, 548, 13, 28705, 345, 15205, 28733, 391, 28733, 22698, 28733, 13082, 497, 1264, 345, 28734, 28723, 28734, 548, 13, 28705, 345, 15205, 28733, 391, 28733, 22698, 28733, 13082, 497, 28733, 5552, 3164, 1264, 345, 28740, 28734, 28723, 28734, 548, 13, 28705, 345, 16346, 495, 28733, 8060, 1264, 345, 28734, 28723, 28734, 548, 13, 28705, 345, 16346, 495, 28733, 8060, 28733, 5552, 3164, 1264, 345, 28740, 28734, 28723, 28734, 548, 13, 28705, 345, 12714, 973, 28733, 391, 28733, 28711, 1373, 1264, 345, 28740, 28723, 28734, 548, 13, 28705, 345, 12714, 973, 28733, 391, 28733, 28711, 1373, 28733, 5552, 3164, 1264, 345, 28782, 28723, 28734, 548, 13, 28705, 345, 8838, 1264, 345, 1014, 5716, 28742, 28713, 3270, 6355, 5532, 15321, 1927, 354, 3500, 28720, 6410, 28725, 690, 993, 11634, 396, 2145, 297, 20429, 4103, 1063, 442, 2948, 14575, 28264, 297, 272, 3500, 28720, 6410, 28723, 415, 3472, 354, 464, 893, 24100, 3500, 19521, 28742, 12308, 396, 2145, 297, 8222, 304, 8189, 4735, 28725, 5374, 298, 264, 6703, 24492, 354, 464, 12714, 973, 28733, 391, 28733, 28711, 1373, 28742, 395, 22651, 9843, 2940, 298, 272, 5502, 302, 4870, 2758, 442, 9332, 11533, 611, 13, 28752, 2]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset[1]['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6LRa2Zm3m19"
   },
   "source": [
    "Now all the samples should be the same length, `max_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(min([len(x['input_ids']) for x in tokenized_train_dataset]) == max([len(x['input_ids']) for x in tokenized_train_dataset]))\n",
    "assert(min([len(x['input_ids']) for x in tokenized_val_dataset]) == max([len(x['input_ids']) for x in tokenized_val_dataset]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "I55Yo3yy3m19",
    "outputId": "c87e344d-e0f3-4542-afcc-4e2025926d64"
   },
   "outputs": [],
   "source": [
    "# Replaced by asserts above\n",
    "#plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22206"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jP3R4enP3m19"
   },
   "source": [
    "## How does the base model do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vxbl4ACsyRgi"
   },
   "source": [
    "Optionally, you can check how Mistral does on one of your data samples. For example, if you have a dataset of users' biometric data to their health scores, you could test the following `eval_prompt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "gOxnx-cAyRgi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Question:\n",
      "You are a Student Web Activity Analyzer developed to support professionals, including Social Workers, School Psychologists, District Administrators, School Safety Specialists, and related roles. Your primary objective is to meticulously evaluate the online activity of K-12 students and identify specific indicators related to their interests and passions. For each identified indicator, provide a JSON object containing:\n",
      "\n",
      "Presence: Indicate a value of 1 (if the indicator is present) or 0 (if not). Even if only a portion of the data aligns with an indicator, mark it as 1.\n",
      "Confidence: Assign a confidence level on a scale of 1-10 to indicate the certainty level of your analysis.\n",
      "\n",
      "Additionally, please include a note that outlines the rationale behind identifying certain indicators and offers a summary of the analyzed web activity.\n",
      "\n",
      "Adhere to the JSON format outlined in the example output section precisely.\n",
      "\n",
      "Each individual online activity you receive represents one search or interaction on a student's device. Occasionally, searches that include large amounts of text will be summarized. These summaries will be marked with 'S~'. Such summarization typically occurs when students copy and paste extensive text blocks, although other cases may exist. Additional details will be provided in the summary.\n",
      "\n",
      "In situations where the presence of an indicator is ambiguous or if anomalies are present in the data, exercise your best judgment while providing a confidence level that reflects the level of uncertainty.\n",
      "\n",
      "Here are the specific indicators that you should use for this task, with definitions, delimited by single quotes.\n",
      "\n",
      "'sports-and-athletics: participating in physical activities and team sports to promote fitness, teamwork, and sportsmanship.'\n",
      "'environmentalism-and-sustainability: learning about the environment, conservation, and sustainable practices to become responsible global citizens.'\n",
      "'gaming-and-e-sports: engaging in digital gaming and competitive e-sports to develop strategic thinking, problem-solving, and teamwork skills.'\n",
      "'college-and-career: engaging in planning, research, and/or discovery around future college and career opportunities or otherwise demonstrating an interest in college or career activities after high school'\n",
      "'cooking-and-food: investigating cooking or food'\n",
      "'reading-and-literature: exploring the world of books and stories through reading and interpretation.'\n",
      "'writing-and-creative-writing: expressing thoughts, ideas, and imagination through written words and storytelling.'\n",
      "'science-and-technology: investigating the natural world and technological advancements'\n",
      "'mathematics-and-statistics: engaging in problem-solving and numerical analysis to understand patterns, shapes, and quantities.'\n",
      "'history-and-social-studies: discovering past events, cultures, and societies to gain a deeper understanding of the world.'\n",
      "'creative-arts: expressing creativity through various art forms like drawing, painting, sculpture, music, performing arts, and more'\n",
      "'animals-and-nature: reflects a student's enthusiasm and curiosity for studying, observing, or interacting with animals and natural environments, potentially driving academic pursuits, extracurricular activities, or career paths related to biology, ecology, or conservation.'\n",
      "\n",
      "\n",
      "### Search Data:\n",
      "['alexs', 'slope formula', 'aslope']\n",
      "\n",
      "### Example Output:\n",
      "{\n",
      "  \"sports-and-athletics\": \"1\",\n",
      "  \"sports-and-athletics-confidence\": \"6\",\n",
      "  \"environmentalism-and-sustainability\": \"0\",\n",
      "  \"environmentalism-and-sustainability-confidence\": \"8\",\n",
      "  \"gaming-and-e-sports\": \"0\",\n",
      "  \"gaming-and-e-sports-confidence\": \"10\",\n",
      "  \"college-and-career\": \"1\",\n",
      "  \"college-and-career-confidence\": \"7\",\n",
      "  \"cooking-and-food\": \"1\",\n",
      "  \"cooking-and-food-confidence\": \"7\",\n",
      "  \"reading-and-literature\": \"0\",\n",
      "  \"reading-and-literature-confidence\": \"7\",\n",
      "  \"writing-and-creative-writing\": \"1\",\n",
      "  \"writing-and-creative-writing-confidence\": \"8\",\n",
      "  \"science-and-technology\": \"0\",\n",
      "  \"science-and-technology-confidence\": \"10\",\n",
      "  \"mathematics-and-statistics\": \"1\",\n",
      "  \"mathematics-and-statistics-confidence\": \"6\",\n",
      "  \"history-and-social-studies\": \"9\",\n",
      "  \"history-and-social-studies-confidence\": \"0\",\n",
      "  \"creative-arts\": \"1\",\n",
      "  \"creative-arts-confidence\": \"8\",\n",
      "  \"animals-and-nature\": \"1\",\n",
      "  \"animals-and-nature-confidence\": \"9\",\n",
      "  \"note\": \"Detailed Summary Goes Here \"\n",
      "}\n",
      "\n",
      "### Solution:\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = question_func(data.loc[0])\n",
    "print(eval_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "NidIuFXMyRgi",
    "outputId": "b1794b11-9a22-4b0a-e871-7df039ab59fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Question:\n",
      "You are a Student Web Activity Analyzer developed to support professionals, including Social Workers, School Psychologists, District Administrators, School Safety Specialists, and related roles. Your primary objective is to meticulously evaluate the online activity of K-12 students and identify specific indicators related to their interests and passions. For each identified indicator, provide a JSON object containing:\n",
      "\n",
      "Presence: Indicate a value of 1 (if the indicator is present) or 0 (if not). Even if only a portion of the data aligns with an indicator, mark it as 1.\n",
      "Confidence: Assign a confidence level on a scale of 1-10 to indicate the certainty level of your analysis.\n",
      "\n",
      "Additionally, please include a note that outlines the rationale behind identifying certain indicators and offers a summary of the analyzed web activity.\n",
      "\n",
      "Adhere to the JSON format outlined in the example output section precisely.\n",
      "\n",
      "Each individual online activity you receive represents one search or interaction on a student's device. Occasionally, searches that include large amounts of text will be summarized. These summaries will be marked with 'S~'. Such summarization typically occurs when students copy and paste extensive text blocks, although other cases may exist. Additional details will be provided in the summary.\n",
      "\n",
      "In situations where the presence of an indicator is ambiguous or if anomalies are present in the data, exercise your best judgment while providing a confidence level that reflects the level of uncertainty.\n",
      "\n",
      "Here are the specific indicators that you should use for this task, with definitions, delimited by single quotes.\n",
      "\n",
      "'sports-and-athletics: participating in physical activities and team sports to promote fitness, teamwork, and sportsmanship.'\n",
      "'environmentalism-and-sustainability: learning about the environment, conservation, and sustainable practices to become responsible global citizens.'\n",
      "'gaming-and-e-sports: engaging in digital gaming and competitive e-sports to develop strategic thinking, problem-solving, and teamwork skills.'\n",
      "'college-and-career: engaging in planning, research, and/or discovery around future college and career opportunities or otherwise demonstrating an interest in college or career activities after high school'\n",
      "'cooking-and-food: investigating cooking or food'\n",
      "'reading-and-literature: exploring the world of books and stories through reading and interpretation.'\n",
      "'writing-and-creative-writing: expressing thoughts, ideas, and imagination through written words and storytelling.'\n",
      "'science-and-technology: investigating the natural world and technological advancements'\n",
      "'mathematics-and-statistics: engaging in problem-solving and numerical analysis to understand patterns, shapes, and quantities.'\n",
      "'history-and-social-studies: discovering past events, cultures, and societies to gain a deeper understanding of the world.'\n",
      "'creative-arts: expressing creativity through various art forms like drawing, painting, sculpture, music, performing arts, and more'\n",
      "'animals-and-nature: reflects a student's enthusiasm and curiosity for studying, observing, or interacting with animals and natural environments, potentially driving academic pursuits, extracurricular activities, or career paths related to biology, ecology, or conservation.'\n",
      "\n",
      "\n",
      "### Search Data:\n",
      "['alexs', 'slope formula', 'aslope']\n",
      "\n",
      "### Example Output:\n",
      "{\n",
      "  \"sports-and-athletics\": \"1\",\n",
      "  \"sports-and-athletics-confidence\": \"6\",\n",
      "  \"environmentalism-and-sustainability\": \"0\",\n",
      "  \"environmentalism-and-sustainability-confidence\": \"8\",\n",
      "  \"gaming-and-e-sports\": \"0\",\n",
      "  \"gaming-and-e-sports-confidence\": \"10\",\n",
      "  \"college-and-career\": \"1\",\n",
      "  \"college-and-career-confidence\": \"7\",\n",
      "  \"cooking-and-food\": \"1\",\n",
      "  \"cooking-and-food-confidence\": \"7\",\n",
      "  \"reading-and-literature\": \"0\",\n",
      "  \"reading-and-literature-confidence\": \"7\",\n",
      "  \"writing-and-creative-writing\": \"1\",\n",
      "  \"writing-and-creative-writing-confidence\": \"8\",\n",
      "  \"science-and-technology\": \"0\",\n",
      "  \"science-and-technology-confidence\": \"10\",\n",
      "  \"mathematics-and-statistics\": \"1\",\n",
      "  \"mathematics-and-statistics-confidence\": \"6\",\n",
      "  \"history-and-social-studies\": \"9\",\n",
      "  \"history-and-social-studies-confidence\": \"0\",\n",
      "  \"creative-arts\": \"1\",\n",
      "  \"creative-arts-confidence\": \"8\",\n",
      "  \"animals-and-nature\": \"1\",\n",
      "  \"animals-and-nature-confidence\": \"9\",\n",
      "  \"note\": \"Detailed Summary Goes Here \"\n",
      "}\n",
      "\n",
      "### Solution:\n",
      "import json\n",
      "from collections import Counter\n",
      "\n",
      "def analyze_web_activity(search_data):\n",
      "    # Replace this code with your solution\n",
      "    # Initialize variables\n",
      "    indicators = {\n",
      "        'sports-and-athletics': 0,\n",
      "        'environmentalism-and-sustainability': 0,\n",
      "        'gaming-and-e-sports': 0,\n",
      "        'college-and-career': 0,\n",
      "        'cooking-and-food': 0,\n",
      "        'reading-and-literature': 0,\n",
      "        'writing-and-creative-writing': 0,\n",
      "        'science-and-technology': 0,\n",
      "        'mathematics-and-statistics': 0,\n",
      "        'history-and-social-studies': 0,\n",
      "        'creative-arts': 0,\n",
      "        'animals-and-nature': 0\n",
      "    }\n",
      "\n",
      "    # Loop over search data\n",
      "    for search in search_data:\n",
      "        # Check if any of the indicators match the search term\n",
      "        for indicator, count in Coun\n"
     ]
    }
   ],
   "source": [
    "# Re-init the tokenizer so it doesn't add padding or eos token\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AapDoyfAyRgi"
   },
   "source": [
    "## Prepare for Training\n",
    "### Setup LORA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mp2gMi1ZzGET"
   },
   "source": [
    "Now, to start our fine-tuning, we have to apply some preprocessing to the model to prepare it for training. For that use the `prepare_model_for_kbit_training` method from PEFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "a9EUEDAl0ss3"
   },
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "gkIcwsSU01EB"
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUYEpEK-yRgj"
   },
   "source": [
    "Let's print the model to examine its layers, as we will apply QLoRA to all the linear layers of the model. Those layers are `q_proj`, `k_proj`, `v_proj`, `o_proj`, `gate_proj`, `up_proj`, `down_proj`, and `lm_head`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "XshGNsbxyRgj",
    "outputId": "c619b0e8-8516-4d4b-9abe-13eaa3f3b204",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm()\n",
      "        (post_attention_layernorm): MistralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6mTLuQJyRgj"
   },
   "source": [
    "Here we define the LoRA config.\n",
    "\n",
    "`r` is the rank of the low-rank matrix used in the adapters, which thus controls the number of parameters trained. A higher rank will allow for more expressivity, but there is a compute tradeoff.\n",
    "\n",
    "`alpha` is the scaling factor for the learned weights. The weight matrix is scaled by `alpha/r`, and thus a higher value for `alpha` assigns more weight to the LoRA activations.\n",
    "\n",
    "The values used in the QLoRA paper were `r=64` and `lora_alpha=16`, and these are said to generalize well, but we will use `r=32` and `lora_alpha=64` so that we have more emphasis on the new fine-tuned data while also reducing computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Ybeyl20n3dYH",
    "outputId": "6a16c182-04d9-4812-ae81-502a8fe364d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 85041152 || all params: 3837112320 || trainable%: 2.2162799758751914\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_FHi_VLyRgn"
   },
   "source": [
    "See how the model looks different now, with the LoRA adapters added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "IaYMWak4yRgn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MistralForCausalLM(\n",
      "      (model): MistralModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x MistralDecoderLayer(\n",
      "            (self_attn): MistralAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (rotary_emb): MistralRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): MistralMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): MistralRMSNorm()\n",
      "            (post_attention_layernorm): MistralRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): MistralRMSNorm()\n",
      "      )\n",
      "      (lm_head): lora.Linear(\n",
      "        (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.05, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=32, out_features=32000, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05H5MIfjyRgc"
   },
   "source": [
    "### Accelerator\n",
    "\n",
    "Set up the Accelerator. I'm not sure if we really need this for a QLoRA given its [description](https://huggingface.co/docs/accelerate/v0.19.0/en/usage_guides/fsdp) (I have to read more about it) but it seems it can't hurt, and it's helpful to have the code for future reference. You can always comment out the accelerator if you want to try without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "TEzYBadkyRgd"
   },
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "yxSbpKQSLY6B"
   },
   "outputs": [],
   "source": [
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9KNTJZkyRgn"
   },
   "source": [
    "### Setup Weights & Biases\n",
    "Let's use Weights & Biases to track our training metrics. You'll need to apply an API key when prompted. Feel free to skip this if you'd like, and just comment out the `wandb` parameters in the `Trainer` definition below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "DDqUNyIoyRgo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavid-hinkle\u001b[0m (\u001b[33msecurly\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import wandb, os\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = \"discern-finetune\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0MOtwf3zdZp"
   },
   "source": [
    "## Run Training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEe0uWYSyRgo"
   },
   "source": [
    "With that said, a note on training: you can set the `max_steps` to be high initially, and examine at what step your model's performance starts to degrade. There is where you'll find a sweet spot for how many steps to perform. For example, say you start with 1000 steps, and find that at around 500 steps the model starts overfitting, as described above. Therefore, 500 steps would be your sweet spot, so you would use the `checkpoint-500` model repo in your output dir (`mistral-journal-finetune`) as your final model in step 6 below.\n",
    "\n",
    "If you're just doing something for fun like I did and are OK with overfitting, you can try different checkpoint versions with different degrees of overfitting.\n",
    "\n",
    "You can interrupt the process via Kernel -> Interrupt Kernel in the top nav bar once you realize you didn't need to train anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "c_L1131GyRgo"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='mistralai/Mistral-7B-v0.1', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "jq0nX33BmfaC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/opt/notebooks/wandb/run-20231208_041139-zfq2fe38</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/securly/discern-finetune/runs/zfq2fe38' target=\"_blank\">mistral-discern-finetune-2023-12-08-04-11</a></strong> to <a href='https://wandb.ai/securly/discern-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/securly/discern-finetune' target=\"_blank\">https://wandb.ai/securly/discern-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/securly/discern-finetune/runs/zfq2fe38' target=\"_blank\">https://wandb.ai/securly/discern-finetune/runs/zfq2fe38</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11417' max='1000000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  11417/1000000 14:37:44 < 1266:56:06, 0.22 it/s, Epoch 1.03/91]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.387400</td>\n",
       "      <td>0.422027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.428300</td>\n",
       "      <td>0.410518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.353200</td>\n",
       "      <td>0.404573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.349600</td>\n",
       "      <td>0.398369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.329800</td>\n",
       "      <td>0.394410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.331700</td>\n",
       "      <td>0.391068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.370300</td>\n",
       "      <td>0.388334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.358900</td>\n",
       "      <td>0.386018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.376800</td>\n",
       "      <td>0.384440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.352700</td>\n",
       "      <td>0.382585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.342600</td>\n",
       "      <td>0.380896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 37\u001b[0m\n\u001b[1;32m      9\u001b[0m trainer \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     10\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     11\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized_train_dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mtransformers\u001b[38;5;241m.\u001b[39mDataCollatorForLanguageModeling(tokenizer, mlm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# silence the warnings. Please re-enable for inference!\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer.py:1533\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1534\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   1535\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1536\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   1537\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1538\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer.py:1847\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1847\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1850\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1852\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1853\u001b[0m ):\n\u001b[1;32m   1854\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1855\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer.py:2713\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2711\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   2712\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2713\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss)\n\u001b[1;32m   2715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/accelerate/accelerator.py:1905\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1903\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1904\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1905\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"discern-finetune\"\n",
    "base_model_name = \"mistral\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=1000000,\n",
    "        learning_rate=2.5e-5, # Want a small lr for finetuning\n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,              # When to start reporting loss\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=200,                # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=1000,               # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\",          # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D57XqcsyRgo"
   },
   "source": [
    "## Try the Trained Model!\n",
    "\n",
    "It's a good idea to kill the current process so that you don't run out of memory loading the base model again on top of the model we just trained. Go to `Kernel > Restart Kernel` or kill the process via the Terminal (`nvidia smi` > `kill [PID]`). \n",
    "\n",
    "By default, the PEFT library will only save the QLoRA adapters, so we need to first load the base model from the Huggingface Hub.\n",
    "\n",
    "### Load the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "fb8230fb86884aa6be318e2d03a88af2"
     ]
    },
    "id": "SKSnF016yRgp",
    "outputId": "bce5209d-90da-4117-c6ac-cda9f3cb3422"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8a2e3403734a678124cfd6e20f5743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BxOhAiqyRgp"
   },
   "source": [
    "### Load the Trained QLora Adapter\n",
    "\n",
    "Now load the QLoRA adapter from the appropriate checkpoint directory, i.e. the best performing model checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GwsiqhWuyRgp"
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"mistral-discern-finetune/checkpoint-11000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's load the eval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "eval_dataset = load_dataset(\"json\", data_files='./validation_data.jsonl', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out a random validation set member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "lMkVNEUvyRgp",
    "outputId": "7d49d409-5dbe-4306-c1a4-9d87e3073397"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral Anaswer:\n",
      "### Question:\n",
      "You are a Student Web Activity Analyzer developed to support professionals, including Social Workers, School Psychologists, District Administrators, School Safety Specialists, and related roles. Your primary objective is to meticulously evaluate the online activity of K-12 students and identify specific indicators related to their interests and passions. For each identified indicator, provide a JSON object containing:\n",
      "\n",
      "Presence: A value of 1 (if the indicator is present) or 0 (if not). Mark as 1 even if only part of the data aligns with an indicator.\n",
      "Confidence: Provide a confidence level on a scale of 1-10 to indicate your level of certainty in the analysis.\n",
      "Note: Include information on the logic used to decide that certain indicators were identified and a summary of the analyzed web activity.\n",
      "\n",
      "Consider patterns in the data, not just individual searches.\n",
      "\n",
      "Consider that the online activity originates from a school-issued device.\n",
      "\n",
      "If ambiguous use your best judgment, reflect uncertainty in confidence score.\n",
      "\n",
      "Here are the specific indicators for this task:\n",
      "\n",
      "'sports-and-athletics'\n",
      "'environmentalism-and-sustainability'\n",
      "'gaming-and-e-sports'\n",
      "'college-and-career'\n",
      "'cooking-and-food'\n",
      "'reading-and-literature'\n",
      "'writing-and-creative-writing'\n",
      "'science-and-technology'\n",
      "'mathematics-and-statistics'\n",
      "'creative-arts'\n",
      "'animals-and-nature'\n",
      "'history-and-social-studies'\n",
      "\n",
      "\n",
      "### Search Data:\n",
      "['memorization definition', 'memorization in a sentence', 'memorization in a sentence that a 6th grader uses', 'memorization in a sentence ', 'memorization in a sentence easy', 'commemorate in a sentence easy', 'aviation in a sentence easy', 'aviary in a sentence easy', 'aviatrix in a sentence easy', 'new moonlight liks', 'pokemon showdown', 'poke pokemon', 'mesopotamia location', 'mesopotamia money', 'ziggurats', 'ziggurat picture drawing', 'ziggurat picture drawing 3d', 'ziggurat picture drawing 3d easy', 'play spontaneous', 'mpontaneous', 'mesopotamia government', 'mesopotamia government building', 'mesopotamia government building easy drawing', 'mesopotamia government building ', 'hollow knight', 'hollow knight playthrough', 'hollow knight speedrun', 'hollow knight speedrun', 'hollow knight speedrun', 'hollow knight 5 endings ', 'mesopotamia location', 'mesopotamia house', 'stuff', 'ziggurat picture drawing 3d easy', 'ziggurat picture drawing 3d easy colored', 'drift boss', 'school bell', 'flag', 'flag that is not rea;', 'flag that is not real;', 'death flag', 'fag', 'google translate', 'google translate', 'red is susu', 'flag that is not rea;', 'flag that is not real;', 'monkey songs', 'monkey sounds', 'augus leavengood', 'august leavengood', 'what is the averge age people dei', 'when will a die', 'cole', 'athletic.net', 'the ponia notes to beemix by groovydominoes52', 'mesopotamia house', 'max and the midknights', 'max and the midknights 4', 'max and the midknights saying by', 'max and the midknights saying by', 'max and the midknights saying by', 'knight', 'snowrider3d', 'snow-rider-3d.github', 'chrishmis tree', 'christmas tree drawing', 'komodo dragons', 'komodo dragon venom effects', 'komodo dragon venom when was it discovered', 'sa', '1000 word essay', 'venomenis', 'venomous', 'in holes is mary lou a boy or gorl', 'how do you make a french', 'fence', 'how to find herobrin', 'how to find herobrine', 'how to find herobrine seed', 'sharecropper']\n",
      "\n",
      "### Example Output:\n",
      "{\n",
      "  \"sports-and-athletics\": \"1\",\n",
      "  \"sports-and-athletics-confidence\": \"6\",\n",
      "  \"environmentalism-and-sustainability\": \"0\",\n",
      "  \"environmentalism-and-sustainability-confidence\": \"8\",\n",
      "  \"gaming-and-e-sports\": \"0\",\n",
      "  \"gaming-and-e-sports-confidence\": \"10\",\n",
      "  \"college-and-career\": \"1\",\n",
      "  \"college-and-career-confidence\": \"7\",\n",
      "  \"cooking-and-food\": \"1\",\n",
      "  \"cooking-and-food-confidence\": \"7\",\n",
      "  \"reading-and-literature\": \"0\",\n",
      "  \"reading-and-literature-confidence\": \"7\",\n",
      "  \"writing-and-creative-writing\": \"1\",\n",
      "  \"writing-and-creative-writing-confidence\": \"8\",\n",
      "  \"science-and-technology\": \"0\",\n",
      "  \"science-and-technology-confidence\": \"10\",\n",
      "  \"mathematics-and-statistics\": \"1\",\n",
      "  \"mathematics-and-statistics-confidence\": \"6\",\n",
      "  \"creative-arts\": \"1\",\n",
      "  \"creative-arts-confidence\": \"8\",\n",
      "  \"animals-and-nature\": \"1\",\n",
      "  \"animals-and-nature-confidence\": \"9\",\n",
      "  \"history-and-social-studies\": \"0\",\n",
      "  \"history-and-social-studies-confidence\": \"9\",\n",
      "  \"note\": \"Detailed Summary Goes Here \"\n",
      "}\n",
      "\n",
      "### Solution:\n",
      "{\n",
      "  \"sports-and-athletics\": \"1.0\",\n",
      "  \"sports-and-athletics-confidence\": \"4.0\",\n",
      "  \"environmentalism-and-sustainability\": \"0.0\",\n",
      "  \"environmentalism-and-sustainability-confidence\": \"10.0\",\n",
      "  \"gaming-and-e-sports\": \"1.0\",\n",
      "  \"gaming-and-e-sports-confidence\": \"9.0\",\n",
      "  \"college-and-career\": \"0.0\",\n",
      "  \"college-and-career-confidence\": \"10.0\",\n",
      "  \"cooking-and-food\": \"0.0\",\n",
      "  \"cooking-and-food-confidence\": \"10.0\",\n",
      "  \"reading-and-literature\": \"1.0\",\n",
      "  \"reading-and-literature-confidence\": \"7.0\",\n",
      "  \"writing-and-creative-writing\": \"1.0\",\n",
      "  \"writing-and-creative-writing-confidence\": \"8.0\",\n",
      "  \"science-and-technology\": \"0.0\",\n",
      "  \"science-and-technology-confidence\": \"10.0\",\n",
      "  \"mathematics-and-statistics\": \"0.0\",\n",
      "  \"mathematics-and-statistics-confidence\": \"10.0\",\n",
      "  \"history-and-social-studies\": \"1.0\",\n",
      "  \"history-and-social-studies-confidence\": \"8.0\",\n",
      "  \"creative-arts\": \"1.0\",\n",
      "  \"creative-arts-confidence\": \"7.0\",\n",
      "  \"animals-and-nature\": \"1.0\",\n",
      "  \"animals-and-nature-confidence\": \"5.0\",\n",
      "  \"note\": \"The student showed interest in sports through a search about athletic.net, indicating some engagement with athletics, though the confidence is moderate due to limited data. Gaming interest is evident from multiple searches related to PokÃ©mon and Hollow Knight, suggesting a strong inclination towards gaming and e-sports. Literature interest is indicated by repeated searches for 'Max and the Midknights,' a book series. Creative writing is suggested by searches for words like 'memorization' and 'commemorate' in sentences, possibly for a writing assignment. The student also searched for creative arts content such as drawings of ziggurats and Christmas trees. Interest in animals is shown by searches about komodo dragons. History and social studies interest is indicated by multiple searches about Mesopotamia.\"\n",
      "}\n",
      "\n",
      "### Note:\n",
      "The presence of searches related to 'Hollow Knight' suggests a strong interest in gaming, while the repeated searches for 'Max and the Midknights' indicate an interest in reading and literature. The student also engaged with creative activities, as seen in searches for drawings and definitions of words in sentences, which may suggest an interest in writing and creative arts. There is no clear evidence of environmentalism, college and career planning, cooking, science and technology, mathematics, or animals beyond the context of gaming. The search for 'athletic.net' indicates some interest in sports, but the confidence is lower due to the lack of additional supporting data. The student also looked up historical topics related to Mesopotamia, indicating an interest in history and social studies. No significant evidence was found for the other categories.\n",
      "\n",
      "Origional Answer\n",
      "\n",
      "{\n",
      "  \"sports-and-athletics\": \"1.0\",\n",
      "  \"sports-and-athletics-confidence\": \"4.0\",\n",
      "  \"environmentalism-and-sustainability\": \"0.0\",\n",
      "  \"environmentalism-and-sustainability-confidence\": \"10.0\",\n",
      "  \"gaming-and-e-sports\": \"1.0\",\n",
      "  \"gaming-and-e-sports-confidence\": \"9.0\",\n",
      "  \"college-and-career\": \"0.0\",\n",
      "  \"college-and-career-confidence\": \"10.0\",\n",
      "  \"cooking-and-food\": \"0.0\",\n",
      "  \"cooking-and-food-confidence\": \"10.0\",\n",
      "  \"reading-and-literature\": \"1.0\",\n",
      "  \"reading-and-literature-confidence\": \"7.0\",\n",
      "  \"writing-and-creative-writing\": \"1.0\",\n",
      "  \"writing-and-creative-writing-confidence\": \"8.0\",\n",
      "  \"science-and-technology\": \"0.0\",\n",
      "  \"science-and-technology-confidence\": \"10.0\",\n",
      "  \"mathematics-and-statistics\": \"0.0\",\n",
      "  \"mathematics-and-statistics-confidence\": \"10.0\",\n",
      "  \"history-and-social-studies\": \"1.0\",\n",
      "  \"history-and-social-studies-confidence\": \"9.0\",\n",
      "  \"creative-arts\": \"1.0\",\n",
      "  \"creative-arts-confidence\": \"7.0\",\n",
      "  \"animals-and-nature\": \"1.0\",\n",
      "  \"animals-and-nature-confidence\": \"6.0\",\n",
      "  \"note\": \"The student showed interest in sports through searches related to athletics.net, indicating some engagement with sports and athletics. Gaming interest is evident from repeated searches about 'pokemon showdown', 'hollow knight', and other gaming-related terms. Literature interest is shown through searches for 'max and the midknights', a book series. Creative writing is suggested by the focus on using words in sentences and looking up definitions. Creative arts are indicated by searches for drawing ziggurats and Christmas trees. Interest in animals and nature is shown by searches about komodo dragons. History and social studies are reflected in the repeated searches about Mesopotamia, its government, and houses.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt, origional_answer = eval_dataset['document'][2].split(\"### Solution:\")\n",
    "prompt += \"### Solution:\"\n",
    "\n",
    "\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(\"Mistral Anaswer:\")\n",
    "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=1000, repetition_penalty=1.15)[0], skip_special_tokens=True))\n",
    "    print(\"\\nOrigional Answer\")\n",
    "    print(origional_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjPlpRSJ-aSs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
